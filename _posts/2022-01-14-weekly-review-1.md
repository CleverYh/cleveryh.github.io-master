---
layout:     post
title:      "周报 #0x01<br>新的一年向 Effective 前进吧"
subtitle:   Project：删号跑路、修缮博客和糟糕的新冠感染体验
date:       2023-01-16
author:     炸毛
timecost:   15 minutes
heading-font: CamingoCodeRegular
# header-style: black
# header-mask: 0.01
header-img-credit:      CHEN Yuhan
header-img-year:        2021 
header-img-outchain: false
header-img: img/bg/wr1.jpg
# nav-style: invert
catalog: true
mathjax: false
live2d:  false
byncsa:  false
do-not-show-in-index: false
tags:
    - 漫谈
---

## 前言

转眼 2023 年已经过去 3.8% 了。前几天在网上看了很多别人写的的年终和周报，很敬佩这种认真生活的精神，突然有了开始坚持写周报的勇气。尽管我的年终总结还在持续难产中，但还是先写写新年以来的事情吧，这样明年的年终总结或许会比较顺利。

大约写了五千多字，首先总结下这周和上周干的几个不务正业的事情，再谈谈经历过的新冠，最后展望一下新的一年。

本来打算 15 日（星期日）发布此周报，但是因为种种原因拖延了一天，起了个坏头＞﹏＜

## Project：删号跑路

在一个夜晚，我突然想删掉自己的即刻账号。

即刻大概是我现在唯一会打字说话的社交平台，在那上面我大概没有半点掩饰，随意倾倒了自己愚蠢、无知、幼稚的思想。

我通宵翻看了这几年发的东西和别人与我的互动，感觉这么多条内容删掉有点麻烦且可惜。实际上我先前就有隐藏掉以前的东西的想法，大概是这一年在即刻上认识了很多熟人的缘故吧。

```json
{
    "id": "62ea9e354d572a90dd9f147c",
    "type": "ORIGINAL_POST",
    "content": "或许可以出一个功能，就是把账号内容归档然后不让别人看。",
    "createdAt": "2022-08-03T16:22:31.017Z"
}
```

一位即友评论表达了相似的需求，她正在寻找仅一个月可见的设置，可惜没有找到。我回复说，可以考虑注销账号，但是不太舍得以前的动态。即友的建议是把数据都爬下来，但是我后来应该是懒得去做，所以就继续忍着。

下面是一个爬虫外行、 Python 苦手通过土法编码基本实现这个没有设计、低内聚高耦合、代码混乱、面向过程、低性能的“删号跑路”项目的过程。

### 分析请求

在之前的 NLP 课做过一个 [小爬虫任务](https://lzzmm.github.io/2021/10/09/word2vec/#%E7%88%AC%E5%8F%96%E5%92%8C%E8%A7%A3%E6%9E%90%E6%96%87%E7%AB%A0)，这就是我对这个项目所拥有的所有经验和认知。回去翻看了以前的代码，用的是 `requests` 爬 HTML 文档然后用 `BeautifulSoup` 解析出数据。打开 F12 看了一下即刻个人主页的 HTML 文档，感觉很复杂，且还有分段加载什么的，总觉得之前的方法不太能套用在这身上。

我没系统学过爬虫，也没学过任何前端框架，web 的东西也是浅尝辄止，看着头晕，所以打算研究研究客户端和服务端之间的通信。恰好在 DevTools 随便点点就找到了 NetWork，那里详细记载了请求和响应。尝试在网页操作，发现很多操作后都会有一个名为 `graphql` 的请求，点开 response 发现都是服务器返回的 JSON 格式的数据。

研究了这个请求的标头，发现 `cookies` 中有一个 `x-jike-access-token` 字段和一个 `x-jike-refresh-token` 字段，想必前者就是访问服务器的 token 吧，于是模拟了一下客户端，确实收到了 `200` 的回应。

请求标头中并没有任何请求数据的命令，看了下 Payload，碰巧就在这找到了 query 数据的操作。

```json
{
    "operationName": "UnreadNotification",
    "variables": {},
    "query": "query UnreadNotification ..."
}
```

在 request 中加入了 payload，但是却返回了 `400`。这是为啥呢？排查了半天原因，发现浏览器 cookies 中的 `x-jike-access-token` 变了，而我还在用先前的 cookies。用了浏览器的 cookies 果然返回了数据。

我开始逐个查找前面的请求，正巧发现了一个请求中的 payload `"operationName": "refreshToken"`。模拟了那个请求，果然返回了 `x-jike-access-token` 和 `x-jike-refresh-token`。看来如果遇到未授权的错误得刷新一下，然后更新 cookies。

开始研究返回的数据，这里以我一开始研究的通知消息列表为例。返回的数据首先有个 `PageInfo`，里面有 `hasNextPage` 和 `loadMoreKey`，字面意思上来看这应该是请求下一页数据的关键。于是尝试阅读了加载下一页的请求，发现 payload 中的 `variables` 多了 `loadMoreKey`，且和上一条请求返回的此字段值一样，试了一下直接吭哧吭哧给我拉回来一百一十八页的通知消息。

删除内容和爬内容什么的也大概是一样的道理，善于观察的我使用土方法获得了前端请求的一些操作，详见项目仓库的文档。

到这里，爬虫的部分就结束了，剩下的是清洗数据、存储数据、分析数据。为什么突然又要分析数据呢？我也不知道，数据都爬了不用来做点什么实在可惜。

### 数据存储

怎样存这些数据是一个值得思考的问题。我一开始想随便把这些数据原封不动存到 json 文档，但是这样可读性太低了，原始数据返回了很多没用的字段，比如内容、图片的 url，内容的 type 什么的。得先将这些东西洗掉。有两个想法，一个是从获取的 json 对象中删，另一个比较直接是更改上述 payload 中的 query 操作。巧合的是第二个想法 work 了，还认识了 GraphQL。

清洗掉一些没用的字段，得到的 json 文件可读性还行，每行是一条消息或者动态，勉强也可以用于数据挖掘什么的。

#### 存到关系数据库

一个比较直接的想法是把它们存到数据库，但是在 21 年秋季学期数据库课程结束后占地太大的 Microsoft SQL Server 就被我卸了，此时只能重新下一个 MySQL。emmm 其实本来不想用关系数据库的，因为我的数据库知识都忘了，怎么设计表是一项难题。但是转念一想，还是趁此机会复习一下关系数据库吧。

留到后面做吧。

#### 存到 csv

另一个想法是存到 csv 文件里，就像当初搞 NLP 一样。由于数据量不算太大，应该是可以 handle 的。这样相比 json 文档会更易读……大概。但是会出现一个问题，就是需要多个表。比如一条内容有许多可变长度的评论之类，一条消息通知也有可变长的点赞用户之类，一个表很难存的下。这样就又变成关系数据库了。但是如果不考虑点赞的用户和内容下的评论，内容还是可以存到 csv 的，况且内容下的评论全在消息里面。这样比存数据库方便许多，是一个更加可行的方案。

但是后来发现没必要。

### 数据分析

数据库什么的完全不想搞，MySQL Shell 开了三天没关，一行命令都没打。那就偷懒直接读 json 文档然后在字典上做吧 (๑•̀ㅂ•́)و✧

数据里的时间格式是 `datetime`，当然，是字符串的形式。总之花费一点时间在 [文档](https://docs.python.org/zh-cn/3/library/datetime.html) 学了时间的转来转去，然后又弄成了 GMT+8。

其他事情比较简单，都是统计一下的事情，由于数据量非常小因而根本不用在意程序运行效率。所以那部分代码实在不堪入目。

有些动态删除了，所以赞和评论数在读动态的时候不会计算在内，但是读通知的时候这些是会算在里面的。

中英文混着输出老是对不齐。写 C++ 的时候就出现过这种情况但是懒得去解决，先糊弄糊弄，留个函数，以后再说吧。

分析动态的 like 数据总是和消息的不一样，以为是 bug，一发现原来是动态把自己的 like 算进去了。

![wr1-1](/img/in-post/wr/wr1-1.png)

习惯写 C++ 了，分支判断语句老是加括号。最后代码写的也丑不过算是可以用了，就先这样吧。这个小脚本工作量不大但是老是盯着数据发呆，太耗费时间了。

## 《Effective C++》读书笔记

解释一下标题吧，什么是“向 Effective 前进”呢？其实灵感来源于最近在重新阅读和整理读书笔记的《Effective C++》（笔记在 [Effective C++](https://lzzmm.github.io/2023/01/09/effective-cpp/), 目前更新了第一章和第二章，内容大概是对书中内容的简要总结和复述，看着很不 Effective，但是我感觉我会经常~~欣赏~~翻看自己写的东西，总之可以加深自己的理解吧）。

在过去，我的人生和我写的 C++ 一样，很懒散随性低效。最近总是在感叹自己所学太少，之前很多时间都在打游戏和干一些没意义的事情，浪费了大好青春和很多机会。希望新的一年可以更加认真对待生活，少一点懒散，多一点勤奋，总之，新的一年向 Effective 前进吧。

在本周刚开始的两天我花在这读书笔记上面的时间比较多，后来因为搞上面的项目和做家务，没时间继续，于是就暂停了。下周要争取把这个事情做完，然后整理《The Annotated STL Sources》的读书笔记。

## 修缮博客

本周还在做的一个事情是修缮这个博客。2022年只写了一篇，实在惭愧。去年春季学期基本没学什么值得写的东西，又或者说我那时候没有写东西的激情。编译原理一开始有心情好好写写前端，到了后端的寄存器优化的时候虽然挺有趣也学得挺好但是那时没心情写博客了。秋季学期在忙着复习考研。当然根本原因是闲的时候经常打游戏。

博客也年久失修，一些文章看着不适合放在这就删了，同时修改了一些以前 OS 实验的文章的错误。也修改了许多网页代码的 bug。新的一年要努力更新博客，好好学习，多思考，才有产出的基础。

## 重新开始 Leetcode

上周六开启了一些学习计划，然后做每日一题，一天大概花去半小时到一小时的时间。最近经常到晚上十一点多开始写，然后跟赶 deadline 一样。还是循序渐进吧。

## 新的一年从感冒开始

校园疫情在放开后几天迅速蔓延。去年 12 月 20 日左右，一位来往比较多的同学阳了，努力防护了几天，室友也发烧了。于是考研第二天早上，失眠加发烧加头疼加畏寒，人很难受，数学就考砸了。休息了一天后烧退了，感觉身体还行，因为母亲还没阴就想着过两天再回家。

29 日回家后，当天下午就高烧 39.6℃ 好几个小时，吃了布洛芬后转低烧 38.5℃ 左右，一晚上睡不着觉，疯狂咳嗽。到了第二天，喉咙特别疼，烧退了，开始喝中药，头还是很晕。之后几天喉咙慢慢恢复，咳嗽也慢慢变少，但是还是整天没精神。在上海的陈老师寄来了年初他们政府发的抗原。第五天的时候测，刚跑到第一条线第一条线就红起来了，特别明显。第六天颜色变得没那么明显，到了第七天抗原终于阴了。

过了好几天，突然又开始咳嗽，且睡眠质量很差，晚上常常失眠。心肺功能感觉变差许多，直到现在精神也一直不是很好。不过好在相比起来症状算是比较轻，烧也退的比较快。

新的一年要多锻炼身体，希望别再生病了。

## 其他值得记录的小事

去年在毕业论文模板的仓库提了 pr，因为没过代码 CI/CD 的检查合并失败了，代码是没问题的，那个 CI 出问题了。我学了一晚上想给他修好但是最后还是没修。最近有个老哥把它修好了，于是我的 pr 被合并了，挺好。还学了个词 LGTM - Looks good to me。

转阴后的一个晴天傍晚，打算出去逛逛，顺便把洗了的照片送给外婆，挂了个相机出门。在桥下看见个寸头小伙走在桥上，于是给他偷偷拍了张剪影。上了桥，寸头小伙请我帮他拍几张照。拿着相机出门这种情况是常有的，虽然我很不擅长拍人像，但是咔嚓咔嚓拍完他好像很满意。他又想帮我拍几张，于是便聊开了。他说他是外地来的，没带相机出门，遇见此景实在可惜。于是在桥上帮我拍完我又领他去海边看落日，他又帮我拍了照片。日落之后加了微信便溜了。之后看了照片，发现我实在不修边幅，头发没剪，拍之前也没捋顺了，口袋里放着东西也是他提醒才拿出来。以后出门还是注意一下形象比较好。

他给我拍的照片被用在 [About](https://lzzmm.github.io/about/) 页和 GitHub 头像。

临近春节，帮家里和外婆家搞了大扫除，很忙。做了几次饭，两次萝卜炒饭——一次胡萝卜一次白萝卜，搞了一锅乱炖的晚餐，包了顿饺子。太久没做饭厨艺还是有点退步，不过学会了清蒸许多种鱼。在家能顿顿吃海鱼真好呀。

## 下周计划

下周过完就开始春节了，所以下周的家务什么的应该会比这周更多，且晚上要看电视剧《狂飙》和《三体》，所以学习的时间会少一点。

下周计划目标比较简单，先完成《Effective C++》读书笔记，然后保证力扣学习进度。有时间的话开始整理《The Annotated STL Sources》的读书笔记，然后推进毕设。

这周老是熬夜，希望下周能够调整好作息，然后按时写好周报。
